{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statlog DATASET\n",
    "already preprocessed the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql import Row\n",
    "import csv\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "f = open(\"pima/australian.dat\")\n",
    "reader = csv.reader(f,delimiter=' ')\n",
    "ww = []\n",
    "for w in reader:\n",
    "    ww.append(w)\n",
    "\n",
    "data = map(lambda p: Row(label=int(p[0]), a_1=float(p[1]),a_2=float(p[2]), \n",
    "                               label_2=int(p[3]),label_3=int(p[4]),label_4=int(p[5]),\n",
    "                               a_3=float(p[6]),label_5 =int(p[7]),label_6=int(p[8]),\n",
    "                               a_4=float(p[9]),label_7=int(p[10]),label_8=int(p[11]),\n",
    "                               a_5=float(p[12]),a_6=float(p[13]),label_9=int(p[14]))\n",
    "                            ,ww)\n",
    "data = spark.createDataFrame(data)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+----+-----+------+-----+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|  a_1|  a_2|  a_3| a_4|  a_5|   a_6|label|label_2|label_3|label_4|label_5|label_6|label_7|label_8|label_9|\n",
      "+-----+-----+-----+----+-----+------+-----+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|22.08|11.46|1.585| 0.0|100.0|1213.0|    1|      2|      4|      4|      0|      0|      1|      2|      0|\n",
      "|22.67|  7.0|0.165| 0.0|160.0|   1.0|    0|      2|      8|      4|      0|      0|      0|      2|      0|\n",
      "|29.58| 1.75| 1.25| 0.0|280.0|   1.0|    0|      1|      4|      4|      0|      0|      1|      2|      0|\n",
      "|21.67| 11.5|  0.0|11.0|  0.0|   1.0|    0|      1|      5|      3|      1|      1|      1|      2|      1|\n",
      "|20.17| 8.17| 1.96|14.0| 60.0| 159.0|    1|      2|      6|      4|      1|      1|      0|      2|      1|\n",
      "|15.83|0.585|  1.5| 2.0|100.0|   1.0|    0|      2|      8|      8|      1|      1|      0|      2|      1|\n",
      "|17.42|  6.5|0.125| 0.0| 60.0| 101.0|    1|      2|      3|      4|      0|      0|      0|      2|      0|\n",
      "|58.67| 4.46| 3.04| 6.0| 43.0| 561.0|    0|      2|     11|      8|      1|      1|      0|      2|      1|\n",
      "|27.83|  1.0|  3.0| 0.0|176.0| 538.0|    1|      1|      2|      8|      0|      0|      0|      2|      0|\n",
      "|55.75| 7.08| 6.75| 3.0|100.0|  51.0|    0|      2|      4|      8|      1|      1|      1|      2|      0|\n",
      "| 33.5| 1.75|  4.5| 4.0|253.0| 858.0|    1|      2|     14|      8|      1|      1|      1|      2|      1|\n",
      "|41.42|  5.0|  5.0| 6.0|470.0|   1.0|    1|      2|     11|      8|      1|      1|      1|      2|      1|\n",
      "|20.67| 1.25|1.375| 3.0|140.0| 211.0|    1|      1|      8|      8|      1|      1|      1|      2|      0|\n",
      "|34.92|  5.0|  7.5| 6.0|  0.0|1001.0|    1|      2|     14|      8|      1|      1|      1|      2|      1|\n",
      "|58.58| 2.71|2.415| 0.0|320.0|   1.0|    1|      2|      8|      4|      0|      0|      1|      2|      0|\n",
      "|48.08| 6.04| 0.04| 0.0|  0.0|2691.0|    1|      2|      4|      4|      0|      0|      0|      2|      1|\n",
      "|29.58|  4.5|  7.5| 2.0|330.0|   1.0|    1|      2|      9|      4|      1|      1|      1|      2|      1|\n",
      "|18.92|  9.0| 0.75| 2.0| 88.0| 592.0|    0|      2|      6|      4|      1|      1|      0|      2|      1|\n",
      "| 20.0| 1.25|0.125| 0.0|140.0|   5.0|    1|      1|      4|      4|      0|      0|      0|      2|      0|\n",
      "|22.42|5.665|2.585| 7.0|129.0|3258.0|    0|      2|     11|      4|      1|      1|      0|      2|      1|\n",
      "+-----+-----+-----+----+-----+------+-----+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vertorize the Data into feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+-----+----+-----+------+-----+-------+-------+-------+-------+-------+-------+-------+-------+--------------------+\n",
      "|  a_1|  a_2|  a_3| a_4|  a_5|   a_6|label|label_2|label_3|label_4|label_5|label_6|label_7|label_8|label_9|            features|\n",
      "+-----+-----+-----+----+-----+------+-----+-------+-------+-------+-------+-------+-------+-------+-------+--------------------+\n",
      "|22.08|11.46|1.585| 0.0|100.0|1213.0|    1|      2|      4|      4|      0|      0|      1|      2|      0|[22.08,11.46,1.58...|\n",
      "|22.67|  7.0|0.165| 0.0|160.0|   1.0|    0|      2|      8|      4|      0|      0|      0|      2|      0|[22.67,7.0,0.165,...|\n",
      "|29.58| 1.75| 1.25| 0.0|280.0|   1.0|    0|      1|      4|      4|      0|      0|      1|      2|      0|[29.58,1.75,1.25,...|\n",
      "|21.67| 11.5|  0.0|11.0|  0.0|   1.0|    0|      1|      5|      3|      1|      1|      1|      2|      1|[21.67,11.5,0.0,1...|\n",
      "|20.17| 8.17| 1.96|14.0| 60.0| 159.0|    1|      2|      6|      4|      1|      1|      0|      2|      1|[20.17,8.17,1.96,...|\n",
      "|15.83|0.585|  1.5| 2.0|100.0|   1.0|    0|      2|      8|      8|      1|      1|      0|      2|      1|[15.83,0.585,1.5,...|\n",
      "|17.42|  6.5|0.125| 0.0| 60.0| 101.0|    1|      2|      3|      4|      0|      0|      0|      2|      0|[17.42,6.5,0.125,...|\n",
      "|58.67| 4.46| 3.04| 6.0| 43.0| 561.0|    0|      2|     11|      8|      1|      1|      0|      2|      1|[58.67,4.46,3.04,...|\n",
      "|27.83|  1.0|  3.0| 0.0|176.0| 538.0|    1|      1|      2|      8|      0|      0|      0|      2|      0|[27.83,1.0,3.0,0....|\n",
      "|55.75| 7.08| 6.75| 3.0|100.0|  51.0|    0|      2|      4|      8|      1|      1|      1|      2|      0|[55.75,7.08,6.75,...|\n",
      "| 33.5| 1.75|  4.5| 4.0|253.0| 858.0|    1|      2|     14|      8|      1|      1|      1|      2|      1|[33.5,1.75,4.5,4....|\n",
      "|41.42|  5.0|  5.0| 6.0|470.0|   1.0|    1|      2|     11|      8|      1|      1|      1|      2|      1|[41.42,5.0,5.0,6....|\n",
      "|20.67| 1.25|1.375| 3.0|140.0| 211.0|    1|      1|      8|      8|      1|      1|      1|      2|      0|[20.67,1.25,1.375...|\n",
      "|34.92|  5.0|  7.5| 6.0|  0.0|1001.0|    1|      2|     14|      8|      1|      1|      1|      2|      1|[34.92,5.0,7.5,6....|\n",
      "|58.58| 2.71|2.415| 0.0|320.0|   1.0|    1|      2|      8|      4|      0|      0|      1|      2|      0|[58.58,2.71,2.415...|\n",
      "|48.08| 6.04| 0.04| 0.0|  0.0|2691.0|    1|      2|      4|      4|      0|      0|      0|      2|      1|[48.08,6.04,0.04,...|\n",
      "|29.58|  4.5|  7.5| 2.0|330.0|   1.0|    1|      2|      9|      4|      1|      1|      1|      2|      1|[29.58,4.5,7.5,2....|\n",
      "|18.92|  9.0| 0.75| 2.0| 88.0| 592.0|    0|      2|      6|      4|      1|      1|      0|      2|      1|[18.92,9.0,0.75,2...|\n",
      "| 20.0| 1.25|0.125| 0.0|140.0|   5.0|    1|      1|      4|      4|      0|      0|      0|      2|      0|[20.0,1.25,0.125,...|\n",
      "|22.42|5.665|2.585| 7.0|129.0|3258.0|    0|      2|     11|      4|      1|      1|      0|      2|      1|[22.42,5.665,2.58...|\n",
      "+-----+-----+-----+----+-----+------+-----+-------+-------+-------+-------+-------+-------+-------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "label = [\"label\"]\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[x for x in data.columns if x not in label],\n",
    "    outputCol='features')\n",
    "data = assembler.transform(data)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = data.select(\"label\", \"features\").randomSplit([0.8, 0.2], 1234)\n",
    "train = splits[1]\n",
    "test = splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use NaiveBayes method to build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.388791593695\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "nb = NaiveBayes()\n",
    "model = nb.fit(train)\n",
    "predictions = model.transform(test)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use DecisionTree method to build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.647985989492\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "model = dt.fit(train)\n",
    "\n",
    "predictions = model.transform(test)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use RandomForest method to build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of RandomForest= 0.647985989492\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "model = rf.fit(train)\n",
    "\n",
    "predictions = model.transform(test)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\",predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy of RandomForest= \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Naive Bayes model fails when the input data is very independent. And the classifiers used in this experiment give out poor performance on continuous data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
