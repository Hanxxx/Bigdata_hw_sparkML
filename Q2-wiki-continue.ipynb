{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open the file that recorded clean wiki pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|                text|\n",
      "+-----+--------------------+\n",
      "|    0|asia ( ) earth 's...|\n",
      "|    0|unilev ( ) dutch-...|\n",
      "|    0|eurasia combin co...|\n",
      "|    0|eric hoffer ( jul...|\n",
      "|    0|shaman ( shah-men...|\n",
      "|    0|the asian giant h...|\n",
      "|    0|list asian pornog...|\n",
      "|    0|georgia ( ; georg...|\n",
      "|    0|calligraphi ( gre...|\n",
      "|    0|hornet ( insect g...|\n",
      "|    0|asia argento ( it...|\n",
      "|    0|time american wee...|\n",
      "|    0|the pacif war , s...|\n",
      "|    0|the boundari cont...|\n",
      "|    0|the demograph rus...|\n",
      "|    0|thi list common s...|\n",
      "|    0|A humid subtrop c...|\n",
      "|    0|aed albopictu ( s...|\n",
      "|    0|buddhism ( ) reli...|\n",
      "|    0|thi list list wor...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function close>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "import csv\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "f = open(\"wiki_result.csv\")\n",
    "reader = csv.reader(f,delimiter='|')\n",
    "ww = []\n",
    "for w in reader:\n",
    "    ww.append(w)\n",
    "ww= map(lambda p: Row(label=int(p[0]), text=str(p[1])),ww)\n",
    "wikies = spark.createDataFrame(ww)\n",
    "wikies.show()\n",
    "f.close"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|label|                text|               words|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|asia ( ) earth 's...|[asia, (, ), eart...|\n",
      "|    0|unilev ( ) dutch-...|[unilev, (, ), du...|\n",
      "|    0|eurasia combin co...|[eurasia, combin,...|\n",
      "|    0|eric hoffer ( jul...|[eric, hoffer, (,...|\n",
      "|    0|shaman ( shah-men...|[shaman, (, shah-...|\n",
      "|    0|the asian giant h...|[the, asian, gian...|\n",
      "|    0|list asian pornog...|[list, asian, por...|\n",
      "|    0|georgia ( ; georg...|[georgia, (, ;, g...|\n",
      "|    0|calligraphi ( gre...|[calligraphi, (, ...|\n",
      "|    0|hornet ( insect g...|[hornet, (, insec...|\n",
      "|    0|asia argento ( it...|[asia, argento, (...|\n",
      "|    0|time american wee...|[time, american, ...|\n",
      "|    0|the pacif war , s...|[the, pacif, war,...|\n",
      "|    0|the boundari cont...|[the, boundari, c...|\n",
      "|    0|the demograph rus...|[the, demograph, ...|\n",
      "|    0|thi list common s...|[thi, list, commo...|\n",
      "|    0|A humid subtrop c...|[a, humid, subtro...|\n",
      "|    0|aed albopictu ( s...|[aed, albopictu, ...|\n",
      "|    0|buddhism ( ) reli...|[buddhism, (, ), ...|\n",
      "|    0|thi list list wor...|[thi, list, list,...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(wikies)\n",
    "wordsData.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|                text|               words|         rawFeatures|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|    0|asia ( ) earth 's...|[asia, (, ), eart...|(300,[0,1,2,3,4,5...|\n",
      "|    0|unilev ( ) dutch-...|[unilev, (, ), du...|(300,[0,1,2,3,4,6...|\n",
      "|    0|eurasia combin co...|[eurasia, combin,...|(300,[0,1,2,3,4,5...|\n",
      "|    0|eric hoffer ( jul...|[eric, hoffer, (,...|(300,[0,1,2,3,4,5...|\n",
      "|    0|shaman ( shah-men...|[shaman, (, shah-...|(300,[0,1,2,3,4,5...|\n",
      "|    0|the asian giant h...|[the, asian, gian...|(300,[0,1,2,3,4,5...|\n",
      "|    0|list asian pornog...|[list, asian, por...|(300,[1,4,8,10,12...|\n",
      "|    0|georgia ( ; georg...|[georgia, (, ;, g...|(300,[0,1,2,3,4,5...|\n",
      "|    0|calligraphi ( gre...|[calligraphi, (, ...|(300,[0,1,2,3,4,5...|\n",
      "|    0|hornet ( insect g...|[hornet, (, insec...|(300,[0,1,3,4,5,6...|\n",
      "|    0|asia argento ( it...|[asia, argento, (...|(300,[0,1,2,3,4,5...|\n",
      "|    0|time american wee...|[time, american, ...|(300,[0,1,2,3,4,5...|\n",
      "|    0|the pacif war , s...|[the, pacif, war,...|(300,[0,1,2,3,4,5...|\n",
      "|    0|the boundari cont...|[the, boundari, c...|(300,[0,1,2,3,4,5...|\n",
      "|    0|the demograph rus...|[the, demograph, ...|(300,[0,1,2,3,4,5...|\n",
      "|    0|thi list common s...|[thi, list, commo...|(300,[1,4,5,7,9,1...|\n",
      "|    0|A humid subtrop c...|[a, humid, subtro...|(300,[0,1,2,3,4,5...|\n",
      "|    0|aed albopictu ( s...|[aed, albopictu, ...|(300,[0,1,2,3,4,5...|\n",
      "|    0|buddhism ( ) reli...|[buddhism, (, ), ...|(300,[0,1,2,3,4,5...|\n",
      "|    0|thi list list wor...|[thi, list, list,...|(300,[1,2,3,5,6,1...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\",numFeatures=300)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "featurizedData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                text|            features|\n",
      "+--------------------+--------------------+\n",
      "|asia ( ) earth 's...|(300,[0,1,2,3,4,5...|\n",
      "|unilev ( ) dutch-...|(300,[0,1,2,3,4,6...|\n",
      "|eurasia combin co...|(300,[0,1,2,3,4,5...|\n",
      "|eric hoffer ( jul...|(300,[0,1,2,3,4,5...|\n",
      "|shaman ( shah-men...|(300,[0,1,2,3,4,5...|\n",
      "|the asian giant h...|(300,[0,1,2,3,4,5...|\n",
      "|list asian pornog...|(300,[1,4,8,10,12...|\n",
      "|georgia ( ; georg...|(300,[0,1,2,3,4,5...|\n",
      "|calligraphi ( gre...|(300,[0,1,2,3,4,5...|\n",
      "|hornet ( insect g...|(300,[0,1,3,4,5,6...|\n",
      "|asia argento ( it...|(300,[0,1,2,3,4,5...|\n",
      "|time american wee...|(300,[0,1,2,3,4,5...|\n",
      "|the pacif war , s...|(300,[0,1,2,3,4,5...|\n",
      "|the boundari cont...|(300,[0,1,2,3,4,5...|\n",
      "|the demograph rus...|(300,[0,1,2,3,4,5...|\n",
      "|thi list common s...|(300,[1,4,5,7,9,1...|\n",
      "|A humid subtrop c...|(300,[0,1,2,3,4,5...|\n",
      "|aed albopictu ( s...|(300,[0,1,2,3,4,5...|\n",
      "|buddhism ( ) reli...|(300,[0,1,2,3,4,5...|\n",
      "|thi list list wor...|(300,[1,2,3,5,6,1...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "\n",
    "rescaledData.select(\"text\", \"features\").show()\n",
    "rescaledData = rescaledData.select(\"label\",\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Within Set Sum of Squared Errors = 53447.3276304\n",
      "Cluster Centers: \n",
      "[  3.64005606   0.           6.9126512    2.73938205   3.9037373\n",
      "   2.33138898   7.42197374   4.86614262   7.00360714   3.52862577   0.\n",
      "   3.47475518   5.25497411   2.3896737    2.76852441   0.71731246\n",
      "   4.4073333    1.77148904   4.51706615   5.45735621   6.33847393   0.\n",
      "   6.18741141   2.22842045   2.76852441   2.78838379   2.8098329\n",
      "   2.76852441   2.42906735   7.18551901   6.67360095   1.72702476\n",
      "   4.41136294   5.95761387   6.32143761   4.320407     1.47998832\n",
      "   3.52862577   3.04577306   4.95709856   3.20289532   6.69696294\n",
      "   3.60291263   1.39883339   3.1250631    4.17147429   1.76914732\n",
      "   3.32222929   3.06722217   0.58626499   6.32674656   5.42294066\n",
      "   4.95709856   1.93145832   4.42006807   2.89562932   0.           3.49406762\n",
      "   7.41290886   5.77570199   3.95477433   3.14214947   2.65968915\n",
      "   4.07533015   5.25497411   0.           4.7132242    2.71023969\n",
      "   7.55923641   3.00861776   1.63013206   2.25215614   2.56452788\n",
      "   1.58723385   2.42374899   0.           3.98585034   1.79722902\n",
      "   1.58661625   4.1172993    2.9343309    2.33138898   6.57438696\n",
      "   5.25503099   3.68371544   2.9796245    3.98585034   3.46719941\n",
      "   5.1844884    2.9254495    4.42872259   5.52584906   1.77315422\n",
      "   6.98857382   2.46743116   2.31674054   4.43996496   2.97147433   0.\n",
      "   1.51049451   2.3896737    2.62094938   7.25944877   7.03758856\n",
      "   2.31650346   4.03243194   1.58661625   5.3486538    3.73807437\n",
      "   2.6743269    2.18780882   4.36545513   3.23147834   1.30357746\n",
      "   3.96863931   6.64308389   8.95156643   3.64279528   4.4004967\n",
      "   5.82117996   3.90059934   2.35940167   2.76852441   4.19720749\n",
      "   3.61365292   4.72970872   2.78008864   4.80832739   9.36358492\n",
      "   3.49148234   4.90293265   1.80172491  10.0223733    1.73120604   0.\n",
      "   3.78850709   6.16580924   3.50180357   2.09825008   2.85273111\n",
      "   5.63926809   4.58596375   8.45129857   1.51641199   2.04158162\n",
      "   6.06759897   1.89551498   4.4572115    2.38085077   0.           4.22199838\n",
      "   3.25049945  11.96018419   0.           3.00861776   2.63968013\n",
      "   3.32222929   4.01149035   2.63824005   3.16337328   1.73359971\n",
      "   2.89718747   3.63823748   3.15719148   2.91058998   2.08782637   0.\n",
      "   3.95477433   3.34606055   4.13967747   3.32222929   3.1959168\n",
      "   3.15719148   5.82117996   2.23070703   4.42963906   2.50954541\n",
      "   1.64277965   3.46794111   1.89612468   4.72970872   3.84679182\n",
      "   3.15719148   3.03683835   4.83763213   3.81764945   3.8257732\n",
      "  14.93461634   3.67193764   2.57389273   3.3198917    4.73176703\n",
      "   3.08898738   3.12004805  10.24932943   5.05150637   5.75733937\n",
      "   1.96860175   1.89261996   3.93082607   3.38005205   6.33847393\n",
      "   4.7315499    2.27360524   2.50954541   4.60449323   5.11087003\n",
      "  11.24895182   2.80817035   4.55525753   3.97280748   3.26026412\n",
      "   2.36053134   1.01389358   6.39001403   8.14055635   2.01621597\n",
      "   3.26394457   3.45404953   4.36545513   2.4143229    2.70258736\n",
      "   0.92858573   3.19433491   2.6743269    6.63978339   5.02272221\n",
      "   2.68109733   5.53227373   1.36196262   2.42374899   6.57981643\n",
      "   1.65533645   3.46794111   4.63875278   3.8593154    4.31127032\n",
      "   2.54676623   3.52862577   2.59396609   1.66223369   1.92339591\n",
      "   4.60487422   4.38639081   0.92231156   2.13814292   2.19146232\n",
      "   3.79604794   2.21845457   0.39314241   5.79125864   5.38168537\n",
      "   2.95997664   4.38292464   2.91058998   8.23151229   5.07077103\n",
      "   4.43690915   1.13114658   1.15825173   1.7776841   11.70448114\n",
      "   7.83929544   0.           2.55543502   2.42374899   1.95253827\n",
      "   2.04650858   2.87418021   3.15719148   5.50283418   4.61155781\n",
      "   3.84679182   5.67785988   2.23249543   8.41457293   1.76914732\n",
      "   3.90006006   3.95477433   4.06312431   7.31362376   7.74702369\n",
      "   2.8559515    3.96336126   3.72578218   3.00154592   2.23249543\n",
      "   4.36545513   3.4563256    4.35416853   3.38005205   3.00861776\n",
      "   0.67592905   2.08056329   8.98398012   3.64005606   3.00861776\n",
      "   1.41812603   3.04702389   1.84462312]\n",
      "[ 0.8589418   0.          0.86218648  0.53427664  0.92052414  0.77712966\n",
      "  1.35437477  0.78638987  1.02325429  0.71965394  0.          0.67922169\n",
      "  0.97063525  1.00784003  0.60713255  0.30175404  1.22569617  0.7776626\n",
      "  0.54034797  2.42549165  1.04964045  0.          1.04640046  0.45477968\n",
      "  0.38856483  0.63006749  0.33514228  0.78320099  0.97408409  1.10852548\n",
      "  1.40854751  0.31591916  1.14642379  1.43066109  1.18432209  1.11800006\n",
      "  0.40217074  0.97501502  0.49601058  0.99483056  1.44069628  0.87958299\n",
      "  0.95180037  0.52213399  0.65105481  0.6207551   0.46510321  0.70427375\n",
      "  0.74178158  0.17099396  1.27853003  1.17620859  0.84323733  1.91907717\n",
      "  0.51846037  1.26907211  0.          1.28904404  1.07062717  1.01377971\n",
      "  0.85777069  0.80133841  0.53622765  0.57197616  0.99320817  0.\n",
      "  1.68168201  0.74070171  0.8943541   0.82025073  0.7149702   0.63453605\n",
      "  0.55249062  0.49601058  0.67028456  0.          0.83038549  0.41245002\n",
      "  0.38027307  1.09478627  0.46429286  0.6678458   1.06013537  0.96520977\n",
      "  0.82428818  1.10607273  0.83038549  0.53046345  1.44013567  0.83519778\n",
      "  0.79084332  2.79904119  1.16654883  1.70425492  0.94901198  0.55285854\n",
      "  0.94286695  0.97501502  0.          0.43395105  0.65570315  0.56902191\n",
      "  1.0609269   1.17293143  0.46026207  0.64347318  0.21646313  0.76608323\n",
      "  0.59818219  0.50298394  0.69262738  0.84356621  0.79703608  0.31181251\n",
      "  0.97910509  0.98855415  1.13751752  0.6192752   0.78320099  0.97588141\n",
      "  0.58689573  0.55410191  0.93498412  0.76608323  0.97141207  0.85271191\n",
      "  1.00333586  0.7776626   1.79257819  1.33871109  0.72739215  0.7641244\n",
      "  0.82391132  0.2816371   0.          1.14140919  0.85120358  0.90955937\n",
      "  0.74070171  0.77306153  0.75796614  2.51742719  1.21893729  0.43877662\n",
      "  0.31324943  0.68847384  0.41830037  0.68096287  0.65241031  0.\n",
      "  1.36487016  0.48531763  1.1297793   0.          0.5881043   1.18177169\n",
      "  0.83177159  1.0214443   0.58091329  0.59313249  0.76747904  1.33871109\n",
      "  0.85271191  0.61131894  0.57794918  0.67221682  0.          0.6207551\n",
      "  0.75518728  0.78646722  1.05641063  0.57644473  0.42560179  1.42118651\n",
      "  0.56303903  0.62534652  0.70156451  0.3890486   0.81962894  0.49660408\n",
      "  0.91903395  0.73463038  1.0214443   0.93583126  1.86389692  0.56463327\n",
      "  1.08335002  1.89293651  0.84998557  0.91605557  0.63479664  1.03843799\n",
      "  0.84830146  1.45478431  1.04127704  1.00596787  0.68539754  0.46429286\n",
      "  0.66726986  0.77342643  0.58036608  1.5010987   0.7582612   0.68815882\n",
      "  0.50494771  1.14140919  0.6230628   0.6192752   0.62891315  0.90946982\n",
      "  0.74432663  0.74178158  0.51606266  0.40952334  0.8962891   1.03272887\n",
      "  0.51388483  0.49177736  0.92728125  1.29171076  0.65774822  0.57197616\n",
      "  0.93632394  0.68096287  1.02918252  1.20327125  1.03123524  0.83177159\n",
      "  0.66726986  0.2720415   0.54963334  0.71175899  0.21122783  1.18997979\n",
      "  0.66322037  0.76448188  0.65241031  0.58742376  0.88215644  2.97884317\n",
      "  0.33480329  0.54034797  0.82391132  0.69625251  0.37089079  0.57045883\n",
      "  0.6422718   1.12036137  0.5060557   0.16237241  1.59527726  0.89694756\n",
      "  1.27800924  1.15299395  0.72006783  1.07062717  0.78927231  1.26952701\n",
      "  0.27876326  0.29939377  0.63748917  0.94901198  1.11712389  0.\n",
      "  0.81904968  0.65687887  0.41892146  0.72006783  0.43345069  1.01370609\n",
      "  1.37381363  0.91605557  0.80141496  1.09189613  0.44755215  1.04127704\n",
      "  0.62013762  0.92084751  0.82391132  0.81262486  1.21893729  0.92548943\n",
      "  0.57070459  1.01998268  0.68995966  0.85271191  0.26911632  0.90946982\n",
      "  0.88113564  0.95627265  0.71965394  0.70417751  0.20116936  0.50047914\n",
      "  1.1994457   1.11430287  1.16847038  0.33054505  0.73901699  0.74178158]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans().setK(2).setSeed(1)\n",
    "model = kmeans.fit(rescaledData)\n",
    "\n",
    "\n",
    "wssse = model.computeCost(rescaledData)\n",
    "print(\"Within Set Sum of Squared Errors = \" + str(wssse))\n",
    "\n",
    "\n",
    "centers = model.clusterCenters()\n",
    "print(\"Cluster Centers: \")\n",
    "for center in centers:\n",
    "    print(center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "At first I took 10 pages for each category. The Error is around 2000.\n",
    "When I finally used 30 pages for each category. The Error increased to 50000.\n",
    "So the model is not effective to cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# next we perform the classification to the wikipages. Question3-wiki:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = rescaledData.select(\"label\", \"features\").randomSplit([0.8, 0.2], 1234)\n",
    "train = splits[1]\n",
    "test = splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.382978723404\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "nb = NaiveBayes()\n",
    "model = nb.fit(train)\n",
    "predictions = model.transform(test)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.382978723404\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "model = dt.fit(train)\n",
    "\n",
    "predictions = model.transform(test)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy of RandomForest= 0.382978723404\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "model = rf.fit(train)\n",
    "\n",
    "predictions = model.transform(test)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\",predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy of RandomForest= \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
